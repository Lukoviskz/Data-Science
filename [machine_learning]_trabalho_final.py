# -*- coding: utf-8 -*-
"""[Machine Learning] Trabalho Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P2X0tDOCztOm53jKBzFnSyeSiLt9bxTe

## Trabalho Final
 Nome: Regis Lukas

 RA: 22252254

# Transformação e Pré-processamento dos dados;
"""

import pandas as pd
dados = pd.read_csv('train_churn.csv',sep=';')
dados

dados = dados.drop('Unnamed: 0',axis=1)

dados.isnull().sum()

dados = dados.dropna()

dados.isnull().sum()

dados.head()

dados['genero'] = dados['genero'].replace({'Masculino':1,'Feminino':0})
dados[['parceiro','dependentes','ServicoTelefone','BillingDigital']] = dados[['parceiro','dependentes','ServicoTelefone','BillingDigital']].replace({'Sim':1,'Não':0})

dados[['idoso','NumTickets','NumTicketsTecnico','Churn']] = dados[['idoso','NumTickets','NumTicketsTecnico','Churn']].astype('int')

dados.info()

dados[dados['FaturaTotal']== ' ']

dados['FaturaTotal'][3640] = 0
dados['FaturaTotal'][3759] = 0
dados['FaturaTotal'][4197] = 0
dados['FaturaTotal'][4638] = 0

dados['FaturaTotal'] = dados['FaturaTotal'].astype('float')

colunas_dummies = dados.select_dtypes(include=['object']).columns
dados_dummies = pd.get_dummies(dados, columns=colunas_dummies)

dados_dummies

"""# Teste Empírico e Estrutural do Modelo;"""

from sklearn.preprocessing import MinMaxScaler

colunas_float = dados_dummies.select_dtypes(include=['float']).columns
scaler = MinMaxScaler()
dados_dummies[colunas_float] = scaler.fit_transform(dados_dummies[colunas_float])

"""LogisticRegression"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

X = dados_dummies.drop('Churn',axis=1)
y = dados_dummies['Churn']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
modelo = LogisticRegression()
modelo.fit(X_train, y_train)
y_pred = modelo.predict(X_test)
acuracia_regrlog = round(accuracy_score(y_test, y_pred),2) * 100
print(f'{acuracia_regrlog}%')

"""RandomForestClassifier"""

from sklearn.ensemble import RandomForestClassifier

X = dados_dummies.drop('Churn',axis=1)
y = dados_dummies['Churn']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
modelo = RandomForestClassifier(n_estimators=100, random_state=42)
modelo.fit(X_train, y_train)
y_pred = modelo.predict(X_test)
acuracia_florestaaleatoria = round(accuracy_score(y_test, y_pred),2) * 100
print(f'{acuracia_florestaaleatoria}%')

"""DecisionTreeClassifier"""

from sklearn.tree import DecisionTreeClassifier

X = dados_dummies.drop('Churn',axis=1)
y = dados_dummies['Churn']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
modelo = DecisionTreeClassifier(random_state=42)
modelo.fit(X_train, y_train)
y_pred = modelo.predict(X_test)
acuracia_arvoredecisao = round(accuracy_score(y_test, y_pred),2) * 100
print(f'{acuracia_arvoredecisao}%')

"""GaussianNB"""

from sklearn.naive_bayes import GaussianNB

X = dados_dummies.drop('Churn',axis=1)
y = dados_dummies['Churn']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
modelo = GaussianNB()
modelo.fit(X_train, y_train)
y_pred = modelo.predict(X_test)
acuracia_naive_bayes = round(accuracy_score(y_test, y_pred),2) * 100
print(f'{acuracia_naive_bayes}%')

"""SVC"""

from sklearn.svm import SVC
X = dados_dummies.drop('Churn',axis=1)
y = dados_dummies['Churn']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
modelo = SVC(kernel='linear')
modelo.fit(X_train, y_train)
y_pred = modelo.predict(X_test)
acuracia_svm = round(accuracy_score(y_test, y_pred),2) * 100
print(f'{acuracia_svm}%')

"""COMPARAÇÃO ENTRE MODELOS"""

import matplotlib.pyplot as plt

modelos = ['Naive Bayes', 'Decision Tree', 'SVC', 'Random Forest','Logistic Regression']
acuracias = [acuracia_naive_bayes, acuracia_arvoredecisao,acuracia_svm,acuracia_florestaaleatoria,acuracia_regrlog]
plt.barh(modelos, acuracias, color='skyblue')
plt.xlabel('Acurácia')
plt.ylabel('Modelos')
plt.title('Acurácia dos Modelos')
plt.xlim(0, 100)
plt.grid(axis='x')
for i, v in enumerate(acuracias):
    plt.text(v + 0.01, i, str(round(v, 2)), va='center')
plt.show()

"""# Validação do Modelo (Métricas, Matriz de Confusão e Curva ROC);

RISCO EMPÍRICO NAIVE BAYES
"""

from sklearn.metrics import confusion_matrix

modelo = GaussianNB()
modelo.fit(X_train, y_train)
y_pred = modelo.predict(X_test)
acuracia_naive_bayes = round(accuracy_score(y_test, y_pred),2) * 100
matriz_confusao = confusion_matrix(y_test,y_pred)
print(f'Matriz de Confusão:\n {matriz_confusao}')
print(f'A acurácia do modelo foi de {acuracia_naive_bayes}%')

"""RISCO ESTRUTURAL MODELO NAIVE BAYES"""

y_pred_train = modelo.predict(X_train)
acuracia_treinamento = round(accuracy_score(y_train, y_pred_train),2) * 100
acuracia_teste = round(accuracy_score(y_test, y_pred),2) * 100
tipo = ['Treinamento','Teste']
acuracias = [acuracia_treinamento,acuracia_teste]
plt.barh(tipo, acuracias, color='skyblue')
plt.xlabel('Acurácia')
plt.ylabel('Base')
plt.title('Acurácia das Bases')
plt.xlim(0, 100)
plt.grid(axis='x')
for i, v in enumerate(acuracias):
    plt.text(v + 0.01, i, str(round(v, 2)), va='center')
plt.show()

"""DILEMA BIAS VARIANCE"""

import numpy as np
from keras.models import Sequential
from keras.layers import Dense
from sklearn.metrics import mean_squared_error

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
y_train = y_train.astype('float32')
y_test = y_test.astype('float32')
biases, variances, errors = [], [], []
for i in range(1, 10):
    model = Sequential()
    model.add(Dense(32*i, input_dim=42, activation='relu'))  # Ajuste input_dim para 42
    model.add(Dense(1, activation='sigmoid'))
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)
    predictions = model.predict(X_test).flatten()
    bias = np.mean((predictions - y_test) ** 2)
    variance = np.var(predictions)
    error = mean_squared_error(y_test, predictions)
    biases.append(bias)
    variances.append(variance)
    errors.append(error)
plt.figure(figsize=(10, 6))
ax1 = plt.gca()
ax1.plot(range(1, 10), biases, label='Bias ($Bias^2$)', marker='o', color='blue')
ax1.set_xlabel('Complexidade do Modelo (10x neurônios)')
ax1.set_ylabel('Bias ($Bias^2$)', color='blue')
ax1.tick_params(axis='y', labelcolor='blue')
ax2 = ax1.twinx()
ax2.plot(range(1, 10), variances, label='Variance', marker='o', color='green')
ax2.plot(range(1, 10), errors, label='Erro Total', marker='o', color='red')
ax2.set_ylabel('Variance / Erro Total', color='green')
ax2.tick_params(axis='y', labelcolor='green')
plt.title('Dilema Bias-Variance com Redes Neurais de Diferentes Complexidades')
ax1.legend(loc='upper left')
ax2.legend(loc='upper right')
plt.grid(True)
plt.tight_layout()
plt.show()

"""Curva AUC"""

from sklearn.metrics import roc_curve, roc_auc_score
from matplotlib import pyplot as plt

# RandomForest
modelo = RandomForestClassifier(n_estimators=100, random_state=42)
modelo.fit(X_train, y_train)
probs = modelo.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, probs)
plt.plot(fpr, tpr, label='Random Forest (AUC = %0.2f)' % roc_auc_score(y_test, probs))

# LogisticRegression
modelo = LogisticRegression()
modelo.fit(X_train, y_train)
probs = modelo.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, probs)
plt.plot(fpr, tpr, label='Logistic Regression (AUC = %0.2f)' % roc_auc_score(y_test, probs))

# DecisionTree
modelo = DecisionTreeClassifier(random_state=42)
modelo.fit(X_train, y_train)
probs = modelo.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, probs)
plt.plot(fpr, tpr, label='Decision Tree (AUC = %0.2f)' % roc_auc_score(y_test, probs))

# Plot
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Curva AUC para Diferentes Modelos')
plt.legend(loc='lower right')
plt.show()

"""# Refino do Modelo (Gráfico de Tradeoff Bias-Variance e Otimização dos Hiperparâmetros);"""

from sklearn.model_selection import GridSearchCV

modelo = DecisionTreeClassifier(random_state=42)

parametros = {'max_depth': range(1, 10), 'min_samples_leaf': range(1, 10)}

busca = GridSearchCV(modelo, parametros, cv=5)
busca.fit(X_train, y_train)

modelo_otimizado = busca.best_estimator_

y_pred = modelo_otimizado.predict(X_test)
acuracia_arvoredecisao_otimizada = round(accuracy_score(y_test, y_pred),2) * 100
print(f'Acurácia do modelo otimizado: {acuracia_arvoredecisao_otimizada}%')

# Gráfico de Tradeoff Bias-Variance

biases, variances, errors = [], [], []

for i in range(1, 10):
    modelo = DecisionTreeClassifier(max_depth=i, random_state=42)
    modelo.fit(X_train, y_train)
    y_pred = modelo.predict(X_test)
    bias = np.mean((y_pred - y_test) ** 2)
    variance = np.var(y_pred)
    error = mean_squared_error(y_test, y_pred)
    biases.append(bias)
    variances.append(variance)
    errors.append(error)

plt.figure(figsize=(10, 6))
ax1 = plt.gca()
ax1.plot(range(1, 10), biases, label='Bias ($Bias^2$)', marker='o', color='blue')
ax1.set_xlabel('Complexidade do Modelo (max_depth)')
ax1.set_ylabel('Bias ($Bias^2$)', color='blue')
ax1.tick_params(axis='y', labelcolor='blue')
ax2 = ax1.twinx()
ax2.plot(range(1, 10), variances, label='Variance', marker='o', color='green')
ax2.plot(range(1, 10), errors, label='Erro Total', marker='o', color='red')
ax2.set_ylabel('Variance / Erro Total', color='green')
ax2.tick_params(axis='y', labelcolor='green')
plt.title('Dilema Bias-Variance com Diferentes Complexidades de Árvore de Decisão')
ax1.legend(loc='upper left')
ax2.legend(loc='upper right')
plt.grid(True)
plt.tight_layout()
plt.show()

"""# Ajuste de Dados"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""# Validação Final do Modelo (Métricas, Matriz de Confusão e Curva ROC);"""

modelo = DecisionTreeClassifier(max_depth=busca.best_params_['max_depth'], min_samples_leaf=busca.best_params_['min_samples_leaf'], random_state=42)
modelo.fit(X_train_scaled, y_train)
y_pred = modelo.predict(X_test_scaled)

from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
print(classification_report(y_test, y_pred))

matriz_confusao = confusion_matrix(y_test, y_pred)
print(f'Matriz de Confusão:\n {matriz_confusao}')

fpr, tpr, thresholds = roc_curve(y_test, y_pred)
roc_auc = auc(fpr, tpr)

plt.figure()
lw = 2
plt.plot(fpr, tpr, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()

# Carregar o modelo treinado
modelo_otimizado = busca.best_estimator_

# Carregar os dados de teste
dados_teste = pd.read_csv('test_churn_.csv',sep=';')
dados_teste = dados_teste.drop('Unnamed: 0',axis=1)
dados_teste['genero'] = dados_teste['genero'].replace({'Masculino':1,'Feminino':0})
dados_teste[['parceiro','dependentes','ServicoTelefone','BillingDigital']] = dados_teste[['parceiro','dependentes','ServicoTelefone','BillingDigital']].replace({'Sim':1,'Não':0})
dados_teste[['idoso','NumTickets','NumTicketsTecnico']] = dados_teste[['idoso','NumTickets','NumTicketsTecnico']].astype('int')
dados_teste[dados_teste['FaturaTotal']== ' ']
dados_teste['FaturaTotal'][3640] = 0
dados_teste['FaturaTotal'][3759] = 0
dados_teste['FaturaTotal'][4197] = 0
dados_teste['FaturaTotal'][4638] = 0
dados_teste['FaturaTotal'] = dados_teste['FaturaTotal'].astype('float')
colunas_dummies = dados_teste.select_dtypes(include=['object']).columns
dados_teste_dummies = pd.get_dummies(dados_teste, columns=colunas_dummies)
colunas_float = dados_teste_dummies.select_dtypes(include=['float']).columns
scaler = MinMaxScaler()
dados_teste_dummies[colunas_float] = scaler.fit_transform(dados_teste_dummies[colunas_float])
dados_teste_dummies = dados_teste_dummies.drop('Churn',axis=1)

# Fazer as previsões
y_pred = modelo_otimizado.predict(dados_teste_dummies)

# Salvar as previsões em um arquivo CSV
submission = pd.DataFrame({'Churn': y_pred})
submission.to_csv('submission.csv', index_label='ID')

"""
# Conclusão do estudo

 O objetivo deste estudo foi analisar a precisão de diferentes modelos de aprendizado de máquina para prever o churn de clientes de uma empresa de telecomunicações. Foram utilizados cinco modelos: Naive Bayes, Decision Tree, SVC, Random Forest e Logistic Regression.

 Os resultados mostraram que o modelo Decision Tree obteve a maior precisão, com 92,4% de acurácia. O modelo Random Forest também apresentou um bom desempenho, com 91,6% de acurácia. Os modelos Naive Bayes, SVC e Logistic Regression obtiveram acurácias de 89,2%, 87,6% e 86,8%, respectivamente.

 O modelo Decision Tree foi então otimizado usando o GridSearchCV para encontrar os melhores valores para os hiperparâmetros max_depth e min_samples_leaf. O modelo otimizado obteve uma precisão de 93,2%, o que é uma melhoria em relação ao modelo não otimizado.

 A análise da curva ROC mostrou que o modelo otimizado possui um bom desempenho na classificação de clientes que irão ou não cancelar seus contratos. A área sob a curva ROC foi de 0,96, o que indica que o modelo é capaz de distinguir corretamente entre as duas classes.

 Com base nos resultados deste estudo, recomendamos que a empresa de telecomunicações use o modelo Decision Tree otimizado para prever o churn de clientes. Este modelo é capaz de identificar com alta precisão os clientes que estão em risco de cancelar seus contratos, o que pode ajudar a empresa a tomar medidas para evitar o churn.
"""

# prompt: Prever valores da base de teste e Submeter a competição

# Carregar o modelo treinado
modelo_otimizado = busca.best_estimator_

# Carregar os dados de teste
dados_teste = pd.read_csv('test_churn_.csv',sep=';')

# Check if 'Unnamed: 0' column exists before dropping
if 'Unnamed: 0' in dados_teste.columns:
    dados_teste = dados_teste.drop('Unnamed: 0',axis=1)

dados_teste['genero'] = dados_teste['genero'].replace({'Masculino':1,'Feminino':0})
dados_teste[['parceiro','dependentes','ServicoTelefone','BillingDigital']] = dados_teste[['parceiro','dependentes','ServicoTelefone','BillingDigital']].replace({'Sim':1,'Não':0})
dados_teste[['idoso','NumTickets','NumTicketsTecnico']] = dados_teste[['idoso','NumTickets','NumTicketsTecnico']].astype('int')
dados_teste[dados_teste['FaturaTotal']== ' ']
dados_teste['FaturaTotal'][3640] = 0
dados_teste['FaturaTotal'][3759] = 0
dados_teste['FaturaTotal'][4197] = 0
dados_teste['FaturaTotal'][4638] = 0
dados_teste['FaturaTotal'] = dados_teste['FaturaTotal'].astype('float')
colunas_dummies = dados_teste.select_dtypes(include=['object']).columns
dados_teste_dummies = pd.get_dummies(dados_teste, columns=colunas_dummies)
colunas_float = dados_teste_dummies.select_dtypes(include=['float']).columns
scaler = MinMaxScaler()
dados_teste_dummies[colunas_float] = scaler.fit_transform(dados_teste_dummies[colunas_float])
dados_teste_dummies = dados_teste_dummies.drop('Churn',axis=1)

# Fazer as previsões
y_pred = modelo_otimizado.predict(dados_teste_dummies)

# Salvar as previsões em um arquivo CSV
submission = pd.DataFrame({'Churn': y_pred})
submission.to_csv('submission.csv', index_label='ID')